{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "super-resolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f95b0de4b2924402b70949b6ef405fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_995b05257236440ea3a545bbd7fe13db",
              "IPY_MODEL_ea23580199024a059bba157a58c58e7e",
              "IPY_MODEL_114c179c6454439098a37dc61227a948"
            ],
            "layout": "IPY_MODEL_f1f86bfafb924bbcabc5af029c172eca"
          }
        },
        "995b05257236440ea3a545bbd7fe13db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc3ad06e2c341eaa1e25629d8950690",
            "placeholder": "​",
            "style": "IPY_MODEL_48e0694590574e67baca425e28b2b505",
            "value": "100%"
          }
        },
        "ea23580199024a059bba157a58c58e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be476eb46d0f4c2991b8e9dcf8ab7d5b",
            "max": 309,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6f117dc7a41465c9a03b25ebefd5863",
            "value": 309
          }
        },
        "114c179c6454439098a37dc61227a948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977c0ece27e04e549a00190a94596b1c",
            "placeholder": "​",
            "style": "IPY_MODEL_1526334823ec434b96ad85e29ca092c8",
            "value": " 309/309 [14:54&lt;00:00,  2.55s/it]"
          }
        },
        "f1f86bfafb924bbcabc5af029c172eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc3ad06e2c341eaa1e25629d8950690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e0694590574e67baca425e28b2b505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be476eb46d0f4c2991b8e9dcf8ab7d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f117dc7a41465c9a03b25ebefd5863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "977c0ece27e04e549a00190a94596b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1526334823ec434b96ad85e29ca092c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BZsJ9CHUvuT",
        "outputId": "11a5454c-f70b-4b92-ecd8-df589ad5af29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading simpsons-faces.zip to /content\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'SRGAN-PyTorch'...\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mu4O06B_eFu8qkZhpVkr5CMQIZ6GZYYb\n",
            "To: /content/SRGAN_x4-ImageNet-c71a4860.pth.tar\n",
            "\r  0%|          | 0.00/6.28M [00:00<?, ?B/s]\r100%|██████████| 6.28M/6.28M [00:00<00:00, 70.2MB/s]\n",
            "\r  0%|          | 0.00/442M [00:00<?, ?B/s]\r  1%|          | 5.00M/442M [00:00<00:11, 38.2MB/s]\r  7%|▋         | 32.0M/442M [00:00<00:02, 161MB/s] \r 12%|█▏        | 51.0M/442M [00:00<00:02, 176MB/s]\r 17%|█▋        | 76.0M/442M [00:00<00:01, 207MB/s]\r 22%|██▏       | 97.0M/442M [00:00<00:01, 196MB/s]\r 27%|██▋       | 121M/442M [00:00<00:01, 212MB/s] \r 32%|███▏      | 142M/442M [00:00<00:01, 198MB/s]\r 39%|███▊      | 171M/442M [00:00<00:01, 228MB/s]\r 44%|████▍     | 196M/442M [00:00<00:01, 237MB/s]\r 50%|████▉     | 220M/442M [00:01<00:00, 235MB/s]\r 55%|█████▌    | 245M/442M [00:01<00:00, 241MB/s]\r 61%|██████    | 269M/442M [00:01<00:00, 201MB/s]\r 67%|██████▋   | 295M/442M [00:01<00:00, 218MB/s]\r 72%|███████▏  | 317M/442M [00:01<00:00, 213MB/s]\r 77%|███████▋  | 339M/442M [00:01<00:00, 205MB/s]\r 83%|████████▎ | 365M/442M [00:01<00:00, 221MB/s]\r 87%|████████▋ | 387M/442M [00:01<00:00, 210MB/s]\r 92%|█████████▏| 409M/442M [00:02<00:00, 211MB/s]\r 99%|█████████▊| 436M/442M [00:02<00:00, 228MB/s]\r100%|██████████| 442M/442M [00:02<00:00, 211MB/s]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/Lornatang/SRGAN-PyTorch\n",
        "mv SRGAN-PyTorch/* .\n",
        "gdown 1Mu4O06B_eFu8qkZhpVkr5CMQIZ6GZYYb\n",
        "\n",
        "mkdir ~/.kaggle\n",
        "mv kaggle.json ~/.kaggle\n",
        "kaggle datasets download -d kostastokis/simpsons-faces\n",
        "\n",
        "unzip -q simpsons-faces.zip\n",
        "mv cropped simpsons-faces-200\n",
        "mkdir simpsons-faces-800"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from typing import Any\n",
        "from tqdm.notebook import tqdm\n",
        "from model import Generator\n",
        "from torchvision.transforms import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "H4wjdrPdALxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image2tensor(image: np.ndarray, range_norm: bool, half: bool) -> torch.Tensor:\n",
        "    \"\"\"Convert the image data type to the Tensor (NCWH) data type supported by PyTorch\n",
        "    Args:\n",
        "        image (np.ndarray): The image data read by ``OpenCV.imread``, the data range is [0,255] or [0, 1]\n",
        "        range_norm (bool): Scale [0, 1] data to between [-1, 1]\n",
        "        half (bool): Whether to convert torch.float32 similarly to torch.half type\n",
        "    Returns:\n",
        "        tensor (torch.Tensor): Data types supported by PyTorch\n",
        "    Examples:\n",
        "        >>> example_image = cv2.imread(\"lr_image.bmp\")\n",
        "        >>> example_tensor = image2tensor(example_image, range_norm=True, half=False)\n",
        "    \"\"\"\n",
        "    # Convert image data type to Tensor data type\n",
        "    tensor = F.to_tensor(image)\n",
        "\n",
        "    # Scale the image data from [0, 1] to [-1, 1]\n",
        "    if range_norm:\n",
        "        tensor = tensor.mul(2.0).sub(1.0)\n",
        "\n",
        "    # Convert torch.float32 image data type to torch.half image data type\n",
        "    if half:\n",
        "        tensor = tensor.half()\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor2image(tensor: torch.Tensor, range_norm: bool, half: bool) -> Any:\n",
        "    \"\"\"Convert the Tensor(NCWH) data type supported by PyTorch to the np.ndarray(WHC) image data type\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Data types supported by PyTorch (NCHW), the data range is [0, 1]\n",
        "        range_norm (bool): Scale [-1, 1] data to between [0, 1]\n",
        "        half (bool): Whether to convert torch.float32 similarly to torch.half type.\n",
        "    Returns:\n",
        "        image (np.ndarray): Data types supported by PIL or OpenCV\n",
        "    Examples:\n",
        "        >>> example_image = cv2.imread(\"lr_image.bmp\")\n",
        "        >>> example_tensor = image2tensor(example_image, range_norm=False, half=False)\n",
        "    \"\"\"\n",
        "    if range_norm:\n",
        "        tensor = tensor.add(1.0).div(2.0)\n",
        "    if half:\n",
        "        tensor = tensor.half()\n",
        "\n",
        "    image = tensor.permute(1, 2, 0).mul(255).clamp(0, 255).cpu().numpy().astype(\"uint8\")\n",
        "    return image"
      ],
      "metadata": {
        "id": "-gAJcObgX492"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperResDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.files = os.listdir(root)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        path = os.path.join(self.root, self.files[item])\n",
        "        image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image2tensor(image, range_norm=False, half=True)\n",
        "        return image, self.files[item]\n",
        "\n",
        "\n",
        "def save_image(image_tensor, path, filename):\n",
        "    image = tensor2image(image_tensor, range_norm=False, half=True)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(os.path.join(path, filename), image)"
      ],
      "metadata": {
        "id": "ZgOtjJXig-7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'simpsons-faces-200'\n",
        "out_path = 'simpsons-faces-800'\n",
        "model_path = 'SRGAN_x4-ImageNet-c71a4860.pth.tar'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Generator().to(device=device, memory_format=torch.channels_last)\n",
        "print(\"Build SRGAN model successfully.\")\n",
        "\n",
        "# Load the super-resolution model weights\n",
        "checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "print(f\"Load SRGAN model weights `{os.path.abspath(model_path)}` successfully.\")\n",
        "\n",
        "model.eval()\n",
        "model.half()\n",
        "\n",
        "dataset = SuperResDataset(data_path)\n",
        "dataloader = DataLoader(dataset, batch_size=32, num_workers=2, shuffle=False)\n",
        "\n",
        "for images, filenames in tqdm(dataloader):\n",
        "    images = images.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
        "    with torch.no_grad():\n",
        "        images = model(images)\n",
        "\n",
        "    for image, filename in zip(images, filenames):\n",
        "        save_image(image, out_path, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f95b0de4b2924402b70949b6ef405fef",
            "995b05257236440ea3a545bbd7fe13db",
            "ea23580199024a059bba157a58c58e7e",
            "114c179c6454439098a37dc61227a948",
            "f1f86bfafb924bbcabc5af029c172eca",
            "6bc3ad06e2c341eaa1e25629d8950690",
            "48e0694590574e67baca425e28b2b505",
            "be476eb46d0f4c2991b8e9dcf8ab7d5b",
            "f6f117dc7a41465c9a03b25ebefd5863",
            "977c0ece27e04e549a00190a94596b1c",
            "1526334823ec434b96ad85e29ca092c8"
          ]
        },
        "id": "QJFi5Uh9XEVG",
        "outputId": "bca02ac0-6bd5-4f54-ae98-0286ef87cecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build SRGAN model successfully.\n",
            "Load SRGAN model weights `/content/SRGAN_x4-ImageNet-c71a4860.pth.tar` successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/309 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f95b0de4b2924402b70949b6ef405fef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbu6rFVDLX7A",
        "outputId": "b07ac86b-4355-4bca-d489-52bb521b32fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "tar czf simpsons-faces-800.tar.gz simpsons-faces-800\n",
        "mv simpsons-faces-800.tar.gz drive/MyDrive/"
      ],
      "metadata": {
        "id": "uLKtsu30Y9OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-TU_sYGKW7Mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}